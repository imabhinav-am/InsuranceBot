{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:mood_affirm\n",
    "- yes\n",
    "- indeed\n",
    "- of course\n",
    "- that sounds good\n",
    "- correct\n",
    "\n",
    "## intent:mood_deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "\n",
    "## intent:mood_great\n",
    "- perfect\n",
    "- very good\n",
    "- great\n",
    "- amazing\n",
    "- feeling like a king\n",
    "- wonderful\n",
    "- I am feeling very good\n",
    "- I am great\n",
    "- I am amazing\n",
    "- I am going to save the world\n",
    "- super\n",
    "- extremely good\n",
    "- so so perfect\n",
    "- so good\n",
    "- so perfect\n",
    "\n",
    "## intent:mood_unhappy\n",
    "- my day was horrible\n",
    "- I am sad\n",
    "- I don't feel very well\n",
    "- I am disappointed\n",
    "- super sad\n",
    "- I'm so sad\n",
    "- sad\n",
    "- very sad\n",
    "- unhappy\n",
    "- bad\n",
    "- very bad\n",
    "- awful\n",
    "- terrible\n",
    "- not so good\n",
    "- not very good\n",
    "- extremly sad\n",
    "- so saad\n",
    "- Quite bad - can I get a cute picture of a [bird](group:birds), please?\n",
    "- Really bad and only [doggo](group:shibes) pics and change that.\n",
    "- Not good. The only thing that could make me fell better is a picture of a cute [kitten](group:cats).\n",
    "- so sad. Only the picture of a [puppy](group:shibes) could make it better.\n",
    "- I am very sad. I need a [cat](group:cats) picture.\n",
    "- Extremely sad. Only the cute [doggo](group:shibes) pics can make me feel better.\n",
    "- Bad. Please show me a [bird](group:birds) pic!\n",
    "- Pretty bad to be honest. Can you show me a [puppy](group:shibes) picture to make me fell better?\n",
    "\n",
    "## intent: inform\n",
    "- A [dog](group:shibes)\n",
    "- [dog](group:shibes)\n",
    "- [bird](group:birds)\n",
    "- a [cat](group:cats)\n",
    "- [cat](group:cats)\n",
    "- a [bird](group:birds)\n",
    "- of a [dog](group:shibes)\n",
    "- of a [cat](group:cats)\n",
    "- a [bird](group:birds), please\n",
    "- a [dog](group:shibes), please\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLU Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"                   # loads the spacy language model\n",
    "- name: \"tokenizer_spacy\"             # splits the sentence into tokens\n",
    "- name: \"ner_crf\"                     # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_spacy\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_sklearn\"   # uses the vector representation to classify using SVM\n",
    "- name: \"ner_synonyms\"                # trains the synonyms\n",
    "\"\"\" \n",
    "\n",
    "%store config > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training NLU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.training_data.loading:Training data format of nlu.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 85 (7 distinct intents)\n",
      "\t- Found intents: 'mood_great', 'mood_deny', 'greet', 'mood_affirm', 'inform', 'goodbye', 'mood_unhappy'\n",
      "\t- entity examples: 18 (1 distinct entities)\n",
      "\t- found entities: 'group'\n",
      "\n",
      "INFO:rasa_nlu.utils.spacy_utils:Trying to load spacy model with name 'en'\n",
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:rasa_nlu.model:Starting to train component nlp_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component tokenizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_crf\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_featurizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_classifier_sklearn\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_synonyms\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into '/home/abhi/Study/github/Chatbot-using-RASA/MoodBot/models/nlu/default/MoodBot'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "training_data = load_data(\"nlu.md\")\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "interpreter = trainer.train(training_data)\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"MoodBot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'stories_md' (str) to file 'stories.md'.\n"
     ]
    }
   ],
   "source": [
    "stories_md = \"\"\"\n",
    "## happy path               \n",
    "* greet              \n",
    "  - utter_greet\n",
    "* mood_great               \n",
    "  - utter_happy\n",
    "* mood_affirm\n",
    "  - utter_happy\n",
    "* mood_affirm\n",
    "  - utter_goodbye\n",
    "  \n",
    "## sad path 1               \n",
    "* greet\n",
    "  - utter_greet             \n",
    "* mood_unhappy\n",
    "  - utter_ask_picture\n",
    "* inform{\"animal\":\"dog\"}  \n",
    "  - action_retrieve_image\n",
    "  - utter_did_that_help\n",
    "* mood_affirm\n",
    "  - utter_happy\n",
    "\n",
    "## sad path 2\n",
    "* greet\n",
    "  - utter_greet\n",
    "* mood_unhappy\n",
    "  - utter_ask_picture\n",
    "* inform{\"group\":\"cat\"}\n",
    "  - action_retrieve_image\n",
    "  - utter_did_that_help\n",
    "* mood_deny\n",
    "  - utter_goodbye\n",
    "  \n",
    "## sad path 3\n",
    "* greet\n",
    "  - utter_greet\n",
    "* mood_unhappy{\"group\":\"puppy\"}\n",
    "  - action_retrieve_image\n",
    "  - utter_did_that_help\n",
    "* mood_affirm\n",
    "  - utter_happy\n",
    "  \n",
    "## strange user\n",
    "* mood_affirm\n",
    "  - utter_happy\n",
    "* mood_affirm\n",
    "  - utter_unclear\n",
    "\n",
    "## say goodbye\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## fallback\n",
    "- utter_unclear\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'domain_yml' (str) to file 'domain.yml'.\n"
     ]
    }
   ],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "- greet\n",
    "- goodbye\n",
    "- mood_affirm\n",
    "- mood_deny\n",
    "- mood_great\n",
    "- mood_unhappy\n",
    "- inform\n",
    "\n",
    "slots:\n",
    "  group:\n",
    "    type: text\n",
    "    \n",
    "entities:\n",
    "- group\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_did_that_help\n",
    "- utter_happy\n",
    "- utter_goodbye\n",
    "- utter_unclear\n",
    "- utter_ask_picture\n",
    "- action_retrieve_image\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! How are you?\"\n",
    "\n",
    "  utter_did_that_help:\n",
    "  - text: \"Did that help you?\"\n",
    "\n",
    "  utter_unclear:\n",
    "  - text: \"I am not sure what you are aiming for.\"\n",
    "  \n",
    "  utter_happy:\n",
    "  - text: \"Great carry on!\"\n",
    "\n",
    "  utter_goodbye:\n",
    "  - text: \"Bye\"\n",
    "  \n",
    "  utter_ask_picture:\n",
    "  - text: \"To cheer you up, I can show you a cute picture of a dog, cat or a bird. Which one do you choose?\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Dialogue Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed Story Blocks: 100%|██████████| 7/7 [00:00<00:00, 609.07it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|██████████| 7/7 [00:00<00:00, 277.55it/s, # trackers=7]\n",
      "Processed Story Blocks: 100%|██████████| 7/7 [00:00<00:00, 251.24it/s, # trackers=11]\n",
      "Processed Story Blocks: 100%|██████████| 7/7 [00:00<00:00, 254.84it/s, # trackers=12]\n",
      "Processed actions: 240it [00:00, 765.46it/s, # examples=240]\n",
      "INFO:rasa_core.policies.keras_policy:Fitting model with 240 total samples and a validation split of 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 23)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                7168      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 14)                462       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 7,630\n",
      "Trainable params: 7,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.5754 - acc: 0.2333\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 0s 261us/step - loss: 2.4610 - acc: 0.4250\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 0s 210us/step - loss: 2.3325 - acc: 0.4583\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 0s 208us/step - loss: 2.1910 - acc: 0.4667\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 0s 211us/step - loss: 2.0502 - acc: 0.4708\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 0s 211us/step - loss: 1.9285 - acc: 0.4708\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 0s 231us/step - loss: 1.8524 - acc: 0.4708\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 0s 217us/step - loss: 1.7864 - acc: 0.4708\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 0s 403us/step - loss: 1.7659 - acc: 0.4708\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 0s 257us/step - loss: 1.7135 - acc: 0.4708\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 0s 200us/step - loss: 1.6886 - acc: 0.4708\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 0s 193us/step - loss: 1.6626 - acc: 0.4708\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 0s 256us/step - loss: 1.6293 - acc: 0.4708\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 0s 220us/step - loss: 1.6105 - acc: 0.4708\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 0s 216us/step - loss: 1.6028 - acc: 0.4708\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 0s 229us/step - loss: 1.5694 - acc: 0.4708\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 0s 219us/step - loss: 1.5417 - acc: 0.4708\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 0s 218us/step - loss: 1.5274 - acc: 0.4708\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 0s 187us/step - loss: 1.5000 - acc: 0.4667\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 0s 199us/step - loss: 1.4828 - acc: 0.4792\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 0s 207us/step - loss: 1.4580 - acc: 0.4917\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 0s 252us/step - loss: 1.4401 - acc: 0.4917\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 0s 244us/step - loss: 1.4082 - acc: 0.4917\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 0s 218us/step - loss: 1.3895 - acc: 0.5083\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 0s 311us/step - loss: 1.3646 - acc: 0.5167\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 0s 254us/step - loss: 1.3464 - acc: 0.5167\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 0s 265us/step - loss: 1.3248 - acc: 0.5333\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 0s 217us/step - loss: 1.3050 - acc: 0.5375\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 0s 218us/step - loss: 1.2822 - acc: 0.5333\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 0s 199us/step - loss: 1.2566 - acc: 0.5583\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 0s 216us/step - loss: 1.2413 - acc: 0.5542\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 0s 222us/step - loss: 1.2242 - acc: 0.5500\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 0s 207us/step - loss: 1.1960 - acc: 0.5542\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 0s 248us/step - loss: 1.1718 - acc: 0.5625\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 0s 222us/step - loss: 1.1542 - acc: 0.5708\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 0s 215us/step - loss: 1.1203 - acc: 0.5708\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 0s 206us/step - loss: 1.0890 - acc: 0.5750\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 0s 195us/step - loss: 1.0681 - acc: 0.5917\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 0s 249us/step - loss: 1.0611 - acc: 0.6000\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 0s 217us/step - loss: 1.0287 - acc: 0.5917\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 0s 208us/step - loss: 0.9930 - acc: 0.6250\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 0s 230us/step - loss: 0.9902 - acc: 0.6375\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 0s 254us/step - loss: 0.9689 - acc: 0.6333\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 0s 260us/step - loss: 0.9171 - acc: 0.6750\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 0s 223us/step - loss: 0.8882 - acc: 0.6833\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 0s 203us/step - loss: 0.8688 - acc: 0.7000\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 0s 219us/step - loss: 0.8645 - acc: 0.6917\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 0s 270us/step - loss: 0.8236 - acc: 0.7375\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 0s 219us/step - loss: 0.7999 - acc: 0.7542\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 0s 199us/step - loss: 0.7893 - acc: 0.7542\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 0s 196us/step - loss: 0.7665 - acc: 0.7917\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 0s 255us/step - loss: 0.7149 - acc: 0.8375\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 0s 202us/step - loss: 0.7358 - acc: 0.8000\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 0s 285us/step - loss: 0.6791 - acc: 0.8333\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 0s 304us/step - loss: 0.6744 - acc: 0.8375\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 0s 265us/step - loss: 0.6667 - acc: 0.8000\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 0s 313us/step - loss: 0.6177 - acc: 0.8667\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 0s 256us/step - loss: 0.6216 - acc: 0.8542\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 0s 265us/step - loss: 0.6295 - acc: 0.8500\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 0s 268us/step - loss: 0.5703 - acc: 0.8958\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 0s 205us/step - loss: 0.5350 - acc: 0.8875\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 0s 245us/step - loss: 0.5341 - acc: 0.8917\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 0s 257us/step - loss: 0.5259 - acc: 0.8917\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 0s 263us/step - loss: 0.5399 - acc: 0.8833\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 0s 350us/step - loss: 0.5041 - acc: 0.9000\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 0s 349us/step - loss: 0.4952 - acc: 0.8833\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 0s 309us/step - loss: 0.4815 - acc: 0.9083\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 0s 391us/step - loss: 0.4627 - acc: 0.9208\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 0s 429us/step - loss: 0.4476 - acc: 0.8917\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 0s 388us/step - loss: 0.4715 - acc: 0.9042\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 0s 418us/step - loss: 0.4403 - acc: 0.9042\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 0s 325us/step - loss: 0.4364 - acc: 0.9083\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 0s 256us/step - loss: 0.4115 - acc: 0.9125\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 0s 285us/step - loss: 0.3984 - acc: 0.9250\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 0s 405us/step - loss: 0.4011 - acc: 0.9083\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 0s 231us/step - loss: 0.3588 - acc: 0.9500\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 0s 143us/step - loss: 0.3639 - acc: 0.9292\n",
      "Epoch 78/100\n",
      "240/240 [==============================] - 0s 139us/step - loss: 0.3783 - acc: 0.9208\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 0s 187us/step - loss: 0.3461 - acc: 0.9292\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 0s 170us/step - loss: 0.3558 - acc: 0.9333\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 0s 411us/step - loss: 0.3463 - acc: 0.9458\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 0s 210us/step - loss: 0.3542 - acc: 0.9250\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 0s 334us/step - loss: 0.3374 - acc: 0.9250\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 0s 198us/step - loss: 0.3098 - acc: 0.9458\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 0s 198us/step - loss: 0.3298 - acc: 0.9375\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 0s 209us/step - loss: 0.2927 - acc: 0.9500\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 0s 206us/step - loss: 0.3022 - acc: 0.9167\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 0s 197us/step - loss: 0.2940 - acc: 0.9458\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 0s 244us/step - loss: 0.2834 - acc: 0.9333\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 0s 202us/step - loss: 0.2698 - acc: 0.9667\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 0s 306us/step - loss: 0.2671 - acc: 0.9375\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 0s 215us/step - loss: 0.2960 - acc: 0.9417\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 0s 188us/step - loss: 0.2719 - acc: 0.9333\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 0s 192us/step - loss: 0.2901 - acc: 0.9250\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 0s 243us/step - loss: 0.2618 - acc: 0.9583\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 0s 309us/step - loss: 0.2434 - acc: 0.9667\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 0s 237us/step - loss: 0.2738 - acc: 0.9375\n",
      "Epoch 98/100\n",
      "240/240 [==============================] - 0s 197us/step - loss: 0.2373 - acc: 0.9667\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 0s 186us/step - loss: 0.2135 - acc: 0.9625\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 0s 184us/step - loss: 0.2121 - acc: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Done fitting keras policy model\n",
      "INFO:rasa_core.agent:Model directory models/dialogue exists and contains old model files. All files will be overwritten.\n",
      "INFO:rasa_core.agent:Persisted model to '/home/abhi/Study/github/Chatbot-using-RASA/MoodBot/models/dialogue'\n"
     ]
    }
   ],
   "source": [
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "fallback = FallbackPolicy(fallback_action_name=\"utter_unclear\",\n",
    "                          core_threshold=0.2,\n",
    "                          nlu_threshold=0.1)\n",
    "\n",
    "agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(), fallback])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = agent.load_data('stories.md')\n",
    "\n",
    "agent.train(training_data)\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talking to Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    }
   ],
   "source": [
    "#Starting the Bot\n",
    "\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.utils import EndpointConfig\n",
    "from rasa_core.interpreter import RasaNLUInterpreter\n",
    "\n",
    "agent = Agent.load('models/dialogue',interpreter=RasaNLUInterpreter('./models/nlu/default/MoodBot/'),\n",
    "        action_endpoint=EndpointConfig(url=\"http://127.0.0.1:5055/webhook\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot is ready to talk! Type messages here or send 'stop'\n",
      "hi\n",
      "Hey! How are you?\n",
      "fine\n",
      "To cheer you up, I can show you a cute picture of a dog, cat or a bird. Which one do you choose?\n",
      "bird\n",
      "Here is something to cheer you up: https://cdn.shibe.online/birds/348fa9da72c18e7b1fe8d39c9b25f8560509ca43.jpg\n",
      "Did that help you?\n",
      "yes sure\n",
      "Great carry on!\n",
      "bye\n",
      "Hey! How are you?\n",
      "fine\n",
      "To cheer you up, I can show you a cute picture of a dog, cat or a bird. Which one do you choose?\n",
      "dog\n",
      "Here is something to cheer you up: https://cdn.shibe.online/shibes/461a9f705e6a7c8a71041cd4b891d2d2746e2b4c.jpg\n",
      "Did that help you?\n",
      "yes\n",
      "Great carry on!\n",
      "ok\n",
      "Bye\n",
      "bye\n",
      "Hey! How are you?\n"
     ]
    }
   ],
   "source": [
    "print(\"Bot is ready to talk! Type messages here or send 'stop'\")\n",
    "while True:\n",
    "    st = input()\n",
    "    if st == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_text(st)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bot]",
   "language": "python",
   "name": "conda-env-bot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
